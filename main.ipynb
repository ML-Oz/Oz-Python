{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ML-Oz/Oz-Python/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"B5-YmQP4BHCZ"},"source":["# 수 와규 팀"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYQbcNtqEkTQ","executionInfo":{"status":"ok","timestamp":1638257942897,"user_tz":-540,"elapsed":301,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}}},"source":["import datetime\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n","from keras.models import Model, load_model\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","plt.style.use('dark_background')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnjJGvwEGEUX","executionInfo":{"status":"ok","timestamp":1638257943218,"user_tz":-540,"elapsed":4,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"e0a8fa99-7f77-4141-d699-74be06b2da29"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"dVU3i72eGVrB","executionInfo":{"status":"ok","timestamp":1638257944056,"user_tz":-540,"elapsed":2,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}}},"source":["filePath = '/content/drive/MyDrive/Colab Notebooks/기계학습팀플/Oz-Python/'"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z28tu_8dEkVB","executionInfo":{"status":"ok","timestamp":1638257946891,"user_tz":-540,"elapsed":2292,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"3e14a9e4-e44d-47ee-dace-a1fca1ce6f43"},"source":["x_train = np.load(filePath + 'dataset/x_train.npy').astype(np.float32)\n","y_train = np.load(filePath + 'dataset/y_train.npy').astype(np.float32)\n","x_val = np.load(filePath + 'dataset/x_val.npy').astype(np.float32)\n","y_val = np.load(filePath + 'dataset/y_val.npy').astype(np.float32)\n","\n","print(x_train.shape, y_train.shape)\n","print(x_val.shape, y_val.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["(2586, 26, 34, 1) (2586, 1)\n","(288, 26, 34, 1) (288, 1)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7hLHjzgEkWy","executionInfo":{"status":"ok","timestamp":1638257982192,"user_tz":-540,"elapsed":671,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"8d571cd0-5ec6-4c4c-915b-40fc3027ea7e"},"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range = 10,\n","    width_shift_range = 0.2,\n","    height_shift_range = 0.2,\n","    shear_range = 0.2\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow(\n","    x = x_train, y = y_train,\n","    batch_size = 32,\n","    shuffle = True\n",")\n","\n","val_generator = val_datagen.flow(\n","    x = x_val, y = y_val,\n","    batch_size = 32,\n","    shuffle = False\n",")\n","\n","inputs = Input(shape=(26, 34, 1))\n","\n","net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n","net = MaxPooling2D(pool_size=2)(net)\n","\n","net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n","net = MaxPooling2D(pool_size=2)(net)\n","\n","net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n","net = MaxPooling2D(pool_size=2)(net)\n","\n","net = Flatten()(net)\n","\n","net = Dense(512)(net)\n","net = Activation('relu')(net)\n","net = Dense(1)(net)\n","outputs = Activation('sigmoid')(net)\n","\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics =['acc'])\n","\n","model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 26, 34, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 1536)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               786944    \n","                                                                 \n"," activation (Activation)     (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 513       \n","                                                                 \n"," activation_1 (Activation)   (None, 1)                 0         \n","                                                                 \n","=================================================================\n","Total params: 880,129\n","Trainable params: 880,129\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56IaggJmEkYY","executionInfo":{"status":"ok","timestamp":1638261686740,"user_tz":-540,"elapsed":410590,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"e99156b5-8e5d-459e-fa20-d4fe7f0fc615"},"source":["start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n","\n","model.fit_generator(\n","    train_generator, epochs=50, validation_data=val_generator,\n","    callbacks=[\n","      ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/기계학습팀플/Oz-Python/models/%s.h5' %(start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n","      ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n","    ]\n",")"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  import sys\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0533 - acc: 0.9814\n","Epoch 00001: val_acc improved from -inf to 0.98958, saving model to /content/drive/MyDrive/Colab Notebooks/기계학습팀플/Oz-Python/models/2021_11_30_08_34_36.h5\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0533 - acc: 0.9814 - val_loss: 0.0294 - val_acc: 0.9896 - lr: 0.0010\n","Epoch 2/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0285 - acc: 0.9915\n","Epoch 00002: val_acc did not improve from 0.98958\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0285 - acc: 0.9915 - val_loss: 0.0221 - val_acc: 0.9896 - lr: 0.0010\n","Epoch 3/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0287 - acc: 0.9880\n","Epoch 00003: val_acc improved from 0.98958 to 1.00000, saving model to /content/drive/MyDrive/Colab Notebooks/기계학습팀플/Oz-Python/models/2021_11_30_08_34_36.h5\n","81/81 [==============================] - 7s 83ms/step - loss: 0.0287 - acc: 0.9880 - val_loss: 0.0089 - val_acc: 1.0000 - lr: 0.0010\n","Epoch 4/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0271 - acc: 0.9899\n","Epoch 00004: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0271 - acc: 0.9899 - val_loss: 0.0284 - val_acc: 0.9826 - lr: 0.0010\n","Epoch 5/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0252 - acc: 0.9911\n","Epoch 00005: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0252 - acc: 0.9911 - val_loss: 0.0102 - val_acc: 1.0000 - lr: 0.0010\n","Epoch 6/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0245 - acc: 0.9923\n","Epoch 00006: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0245 - acc: 0.9923 - val_loss: 0.0065 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 7/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0280 - acc: 0.9892\n","Epoch 00007: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0280 - acc: 0.9892 - val_loss: 0.0221 - val_acc: 0.9896 - lr: 0.0010\n","Epoch 8/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0288 - acc: 0.9899\n","Epoch 00008: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0288 - acc: 0.9899 - val_loss: 0.0140 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 9/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0217 - acc: 0.9927\n","Epoch 00009: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0217 - acc: 0.9927 - val_loss: 0.0140 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 10/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0160 - acc: 0.9942\n","Epoch 00010: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0160 - acc: 0.9942 - val_loss: 0.0108 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 11/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0320 - acc: 0.9869\n","Epoch 00011: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0320 - acc: 0.9869 - val_loss: 0.0328 - val_acc: 0.9896 - lr: 0.0010\n","Epoch 12/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0214 - acc: 0.9930\n","Epoch 00012: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0214 - acc: 0.9930 - val_loss: 0.0192 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 13/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0155 - acc: 0.9957\n","Epoch 00013: val_acc did not improve from 1.00000\n","\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0155 - acc: 0.9957 - val_loss: 0.0090 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 14/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0077 - acc: 0.9985\n","Epoch 00014: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.0069 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 15/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0082 - acc: 0.9977\n","Epoch 00015: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0092 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 16/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0085 - acc: 0.9977\n","Epoch 00016: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0047 - val_acc: 1.0000 - lr: 2.0000e-04\n","Epoch 17/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9981\n","Epoch 00017: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0064 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 18/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9977\n","Epoch 00018: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0058 - acc: 0.9977 - val_loss: 0.0043 - val_acc: 1.0000 - lr: 2.0000e-04\n","Epoch 19/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9973\n","Epoch 00019: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0074 - acc: 0.9973 - val_loss: 0.0040 - val_acc: 1.0000 - lr: 2.0000e-04\n","Epoch 20/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9985\n","Epoch 00020: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0081 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 1.0000 - lr: 2.0000e-04\n","Epoch 21/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9988\n","Epoch 00021: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0028 - val_acc: 1.0000 - lr: 2.0000e-04\n","Epoch 22/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9985\n","Epoch 00022: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0034 - val_acc: 1.0000 - lr: 2.0000e-04\n","Epoch 23/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9988\n","Epoch 00023: val_acc did not improve from 1.00000\n","\n","Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0041 - val_acc: 1.0000 - lr: 2.0000e-04\n","Epoch 24/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9996\n","Epoch 00024: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 78ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0044 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 25/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0065 - acc: 0.9985\n","Epoch 00025: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.0045 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 26/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0041 - acc: 0.9988\n","Epoch 00026: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0048 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 27/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0057 - acc: 0.9977\n","Epoch 00027: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0057 - acc: 0.9977 - val_loss: 0.0055 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 28/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9985\n","Epoch 00028: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0051 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 29/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0049 - acc: 0.9985\n","Epoch 00029: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0035 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 30/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0026 - acc: 0.9992\n","Epoch 00030: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 80ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0036 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 31/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n","Epoch 00031: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 81ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 32/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0038 - acc: 0.9988\n","Epoch 00032: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0036 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 33/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9981\n","Epoch 00033: val_acc did not improve from 1.00000\n","\n","Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-05.\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 34/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.9992\n","Epoch 00034: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 80ms/step - loss: 0.0043 - acc: 0.9992 - val_loss: 0.0036 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 35/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9996\n","Epoch 00035: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0032 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 36/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9973\n","Epoch 00036: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 79ms/step - loss: 0.0044 - acc: 0.9973 - val_loss: 0.0033 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 37/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9988\n","Epoch 00037: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 80ms/step - loss: 0.0053 - acc: 0.9988 - val_loss: 0.0030 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 38/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0050 - acc: 0.9985\n","Epoch 00038: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0030 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 39/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0037 - acc: 0.9988\n","Epoch 00039: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 80ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0031 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 40/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9992\n","Epoch 00040: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0029 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 41/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.9988\n","Epoch 00041: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0031 - acc: 0.9988 - val_loss: 0.0030 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 42/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9985\n","Epoch 00042: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 80ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0032 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 43/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0035 - acc: 0.9992\n","Epoch 00043: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 80ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0034 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 44/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0028 - acc: 0.9996\n","Epoch 00044: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 81ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0032 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 45/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0033 - acc: 0.9992\n","Epoch 00045: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0034 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 46/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9988\n","Epoch 00046: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.0036 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 47/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9977\n","Epoch 00047: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 81ms/step - loss: 0.0060 - acc: 0.9977 - val_loss: 0.0039 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 48/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0035 - acc: 0.9981\n","Epoch 00048: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 81ms/step - loss: 0.0035 - acc: 0.9981 - val_loss: 0.0036 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 49/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0021 - acc: 0.9996\n","Epoch 00049: val_acc did not improve from 1.00000\n","81/81 [==============================] - 7s 80ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0032 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 50/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0065 - acc: 0.9981\n","Epoch 00050: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 80ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0033 - val_acc: 1.0000 - lr: 1.0000e-05\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f20b9aafa90>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"AJ9ss0XrHs2c","executionInfo":{"status":"ok","timestamp":1638261686741,"user_tz":-540,"elapsed":11,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}}},"source":["from sklearn.metrics import accuracy_score, confusion_matrix\n","import seaborn as sns"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"a3fOYzCXHs3e","executionInfo":{"status":"ok","timestamp":1638261688000,"user_tz":-540,"elapsed":1265,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"73d4f432-8206-4337-c3dd-c52c7e71bcac"},"source":["model = load_model('/content/drive/MyDrive/Colab Notebooks/기계학습팀플/Oz-Python/models/%s.h5' %(start_time))\n","\n","y_pred = model.predict(x_val/255.)\n","y_pred_logical = (y_pred>0.5).astype(np.int)\n","\n","print('test acc: %s' %accuracy_score(y_val, y_pred_logical))\n","cm = confusion_matrix(y_val, y_pred_logical)\n","sns.heatmap(cm, annot=True)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["test acc: 1.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f20bbbbd790>"]},"metadata":{},"execution_count":17},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{}}]}]}