{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ML-Oz/Oz-Python/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"B5-YmQP4BHCZ"},"source":["# 수 와규 팀"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYQbcNtqEkTQ","executionInfo":{"status":"ok","timestamp":1637742840033,"user_tz":-540,"elapsed":3449,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}}},"source":["import datetime\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n","from keras.models import Model, load_model\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","plt.style.use('dark_background')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnjJGvwEGEUX","executionInfo":{"status":"ok","timestamp":1637743158174,"user_tz":-540,"elapsed":15950,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"730cbb6d-9259-4ca7-8151-6f5ef064ef7e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"dVU3i72eGVrB","executionInfo":{"status":"ok","timestamp":1637743416418,"user_tz":-540,"elapsed":276,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}}},"source":["filePath = '/content/drive/MyDrive/Colab Notebooks/기계학습팀플/Oz-Python/'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z28tu_8dEkVB","executionInfo":{"status":"ok","timestamp":1637743417334,"user_tz":-540,"elapsed":5,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"09e5848e-197c-459b-be69-3f7832ddf589"},"source":["x_train = np.load(filePath + 'dataset/x_train.npy').astype(np.float32)\n","y_train = np.load(filePath + 'dataset/y_train.npy').astype(np.float32)\n","x_val = np.load(filePath + 'dataset/x_val.npy').astype(np.float32)\n","y_val = np.load(filePath + 'dataset/y_val.npy').astype(np.float32)\n","\n","print(x_train.shape, y_train.shape)\n","print(x_val.shape, y_val.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(2586, 26, 34, 1) (2586, 1)\n","(288, 26, 34, 1) (288, 1)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7hLHjzgEkWy","executionInfo":{"status":"ok","timestamp":1637743443374,"user_tz":-540,"elapsed":730,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"8eb9badf-db98-46e0-f6e5-df67557b0fa7"},"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range = 10,\n","    width_shift_range = 0.2,\n","    height_shift_range = 0.2,\n","    shear_range = 0.2\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow(\n","    x = x_train, y = y_train,\n","    batch_size = 32,\n","    shuffle = True\n",")\n","\n","val_generator = val_datagen.flow(\n","    x = x_val, y = y_val,\n","    batch_size = 32,\n","    shuffle = False\n",")\n","\n","inputs = Input(shape=(26, 34, 1))\n","\n","net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n","net = MaxPooling2D(pool_size=2)(net)\n","\n","net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n","net = MaxPooling2D(pool_size=2)(net)\n","\n","net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n","net = MaxPooling2D(pool_size=2)(net)\n","\n","net = Flatten()(net)\n","\n","net = Dense(512)(net)\n","net = Activation('relu')(net)\n","net = Dense(1)(net)\n","outputs = Activation('sigmoid')(net)\n","\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics =['acc'])\n","\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 26, 34, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 1536)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               786944    \n","                                                                 \n"," activation (Activation)     (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 513       \n","                                                                 \n"," activation_1 (Activation)   (None, 1)                 0         \n","                                                                 \n","=================================================================\n","Total params: 880,129\n","Trainable params: 880,129\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56IaggJmEkYY","executionInfo":{"status":"ok","timestamp":1637743859739,"user_tz":-540,"elapsed":381474,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"ecd6dcb6-b8f1-4392-a2bd-e91354acf0e1"},"source":["start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n","\n","model.fit_generator(\n","    train_generator, epochs=50, validation_data=val_generator,\n","    callbacks=[\n","      ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n","      ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n","    ]\n",")"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  import sys\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","81/81 [==============================] - ETA: 0s - loss: 0.4988 - acc: 0.7610\n","Epoch 00001: val_acc improved from -inf to 0.89583, saving model to models/2021_11_24_08_44_38.h5\n","81/81 [==============================] - 7s 72ms/step - loss: 0.4988 - acc: 0.7610 - val_loss: 0.2868 - val_acc: 0.8958 - lr: 0.0010\n","Epoch 2/50\n","81/81 [==============================] - ETA: 0s - loss: 0.2888 - acc: 0.8797\n","Epoch 00002: val_acc improved from 0.89583 to 0.95833, saving model to models/2021_11_24_08_44_38.h5\n","81/81 [==============================] - 6s 70ms/step - loss: 0.2888 - acc: 0.8797 - val_loss: 0.1246 - val_acc: 0.9583 - lr: 0.0010\n","Epoch 3/50\n","81/81 [==============================] - ETA: 0s - loss: 0.1854 - acc: 0.9323\n","Epoch 00003: val_acc improved from 0.95833 to 0.97917, saving model to models/2021_11_24_08_44_38.h5\n","81/81 [==============================] - 6s 70ms/step - loss: 0.1854 - acc: 0.9323 - val_loss: 0.0805 - val_acc: 0.9792 - lr: 0.0010\n","Epoch 4/50\n","81/81 [==============================] - ETA: 0s - loss: 0.1682 - acc: 0.9424\n","Epoch 00004: val_acc did not improve from 0.97917\n","81/81 [==============================] - 6s 70ms/step - loss: 0.1682 - acc: 0.9424 - val_loss: 0.0846 - val_acc: 0.9618 - lr: 0.0010\n","Epoch 5/50\n","81/81 [==============================] - ETA: 0s - loss: 0.1041 - acc: 0.9598\n","Epoch 00005: val_acc did not improve from 0.97917\n","81/81 [==============================] - 6s 70ms/step - loss: 0.1041 - acc: 0.9598 - val_loss: 0.0863 - val_acc: 0.9653 - lr: 0.0010\n","Epoch 6/50\n","81/81 [==============================] - ETA: 0s - loss: 0.1003 - acc: 0.9695\n","Epoch 00006: val_acc did not improve from 0.97917\n","81/81 [==============================] - 6s 70ms/step - loss: 0.1003 - acc: 0.9695 - val_loss: 0.0908 - val_acc: 0.9722 - lr: 0.0010\n","Epoch 7/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0930 - acc: 0.9675\n","Epoch 00007: val_acc improved from 0.97917 to 0.98958, saving model to models/2021_11_24_08_44_38.h5\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0930 - acc: 0.9675 - val_loss: 0.0528 - val_acc: 0.9896 - lr: 0.0010\n","Epoch 8/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0837 - acc: 0.9664\n","Epoch 00008: val_acc did not improve from 0.98958\n","81/81 [==============================] - 6s 69ms/step - loss: 0.0837 - acc: 0.9664 - val_loss: 0.0369 - val_acc: 0.9826 - lr: 0.0010\n","Epoch 9/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0742 - acc: 0.9756\n","Epoch 00009: val_acc did not improve from 0.98958\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0742 - acc: 0.9756 - val_loss: 0.0661 - val_acc: 0.9896 - lr: 0.0010\n","Epoch 10/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0616 - acc: 0.9799\n","Epoch 00010: val_acc improved from 0.98958 to 0.99306, saving model to models/2021_11_24_08_44_38.h5\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0616 - acc: 0.9799 - val_loss: 0.0266 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 11/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0862 - acc: 0.9729\n","Epoch 00011: val_acc did not improve from 0.99306\n","81/81 [==============================] - 6s 69ms/step - loss: 0.0862 - acc: 0.9729 - val_loss: 0.0289 - val_acc: 0.9896 - lr: 0.0010\n","Epoch 12/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0539 - acc: 0.9818\n","Epoch 00012: val_acc did not improve from 0.99306\n","81/81 [==============================] - 6s 69ms/step - loss: 0.0539 - acc: 0.9818 - val_loss: 0.0206 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 13/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0534 - acc: 0.9814\n","Epoch 00013: val_acc did not improve from 0.99306\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0534 - acc: 0.9814 - val_loss: 0.0217 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 14/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0425 - acc: 0.9865\n","Epoch 00014: val_acc did not improve from 0.99306\n","81/81 [==============================] - 6s 69ms/step - loss: 0.0425 - acc: 0.9865 - val_loss: 0.0222 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 15/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0380 - acc: 0.9884\n","Epoch 00015: val_acc improved from 0.99306 to 0.99653, saving model to models/2021_11_24_08_44_38.h5\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0380 - acc: 0.9884 - val_loss: 0.0140 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 16/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0430 - acc: 0.9876\n","Epoch 00016: val_acc did not improve from 0.99653\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0430 - acc: 0.9876 - val_loss: 0.0332 - val_acc: 0.9896 - lr: 0.0010\n","Epoch 17/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0376 - acc: 0.9876\n","Epoch 00017: val_acc improved from 0.99653 to 1.00000, saving model to models/2021_11_24_08_44_38.h5\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0376 - acc: 0.9876 - val_loss: 0.0085 - val_acc: 1.0000 - lr: 0.0010\n","Epoch 18/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0345 - acc: 0.9896\n","Epoch 00018: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 69ms/step - loss: 0.0345 - acc: 0.9896 - val_loss: 0.0291 - val_acc: 0.9826 - lr: 0.0010\n","Epoch 19/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0341 - acc: 0.9896\n","Epoch 00019: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 69ms/step - loss: 0.0341 - acc: 0.9896 - val_loss: 0.0268 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 20/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0372 - acc: 0.9888\n","Epoch 00020: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0372 - acc: 0.9888 - val_loss: 0.0164 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 21/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0350 - acc: 0.9899\n","Epoch 00021: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0350 - acc: 0.9899 - val_loss: 0.0161 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 22/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0274 - acc: 0.9915\n","Epoch 00022: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0274 - acc: 0.9915 - val_loss: 0.0251 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 23/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.9896\n","Epoch 00023: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0371 - acc: 0.9896 - val_loss: 0.0110 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 24/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0220 - acc: 0.9927\n","Epoch 00024: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0220 - acc: 0.9927 - val_loss: 0.0130 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 25/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0291 - acc: 0.9896\n","Epoch 00025: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 69ms/step - loss: 0.0291 - acc: 0.9896 - val_loss: 0.0102 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 26/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.9903\n","Epoch 00026: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0261 - acc: 0.9903 - val_loss: 0.0127 - val_acc: 0.9931 - lr: 0.0010\n","Epoch 27/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0149 - acc: 0.9965\n","Epoch 00027: val_acc did not improve from 1.00000\n","\n","Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0106 - val_acc: 0.9965 - lr: 0.0010\n","Epoch 28/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.9961\n","Epoch 00028: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0144 - acc: 0.9961 - val_loss: 0.0094 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 29/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0141 - acc: 0.9950\n","Epoch 00029: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0141 - acc: 0.9950 - val_loss: 0.0090 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 30/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9961\n","Epoch 00030: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0090 - acc: 0.9961 - val_loss: 0.0066 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 31/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0111 - acc: 0.9977\n","Epoch 00031: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0111 - acc: 0.9977 - val_loss: 0.0096 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 32/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.9965\n","Epoch 00032: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0090 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 33/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0063 - acc: 0.9977\n","Epoch 00033: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0063 - acc: 0.9977 - val_loss: 0.0059 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 34/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9977\n","Epoch 00034: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0066 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 35/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0103 - acc: 0.9969\n","Epoch 00035: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0055 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 36/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9969\n","Epoch 00036: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.0039 - val_acc: 0.9965 - lr: 2.0000e-04\n","Epoch 37/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0119 - acc: 0.9969\n","Epoch 00037: val_acc did not improve from 1.00000\n","\n","Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","81/81 [==============================] - 6s 69ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.0040 - val_acc: 1.0000 - lr: 2.0000e-04\n","Epoch 38/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9985\n","Epoch 00038: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.0060 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 39/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9977\n","Epoch 00039: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0060 - acc: 0.9977 - val_loss: 0.0056 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 40/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9965\n","Epoch 00040: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0059 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 41/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9992\n","Epoch 00041: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0048 - acc: 0.9992 - val_loss: 0.0054 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 42/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9969\n","Epoch 00042: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 70ms/step - loss: 0.0075 - acc: 0.9969 - val_loss: 0.0065 - val_acc: 0.9965 - lr: 4.0000e-05\n","Epoch 43/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9988\n","Epoch 00043: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.0039 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 44/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9985\n","Epoch 00044: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0033 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 45/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9988\n","Epoch 00045: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0059 - acc: 0.9988 - val_loss: 0.0028 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 46/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9981\n","Epoch 00046: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 47/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9992\n","Epoch 00047: val_acc did not improve from 1.00000\n","\n","Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-05.\n","81/81 [==============================] - 6s 72ms/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0044 - val_acc: 1.0000 - lr: 4.0000e-05\n","Epoch 48/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.9973\n","Epoch 00048: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0098 - acc: 0.9973 - val_loss: 0.0038 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 49/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9973\n","Epoch 00049: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0040 - val_acc: 1.0000 - lr: 1.0000e-05\n","Epoch 50/50\n","81/81 [==============================] - ETA: 0s - loss: 0.0068 - acc: 0.9973\n","Epoch 00050: val_acc did not improve from 1.00000\n","81/81 [==============================] - 6s 71ms/step - loss: 0.0068 - acc: 0.9973 - val_loss: 0.0038 - val_acc: 1.0000 - lr: 1.0000e-05\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbcbce0cad0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"AJ9ss0XrHs2c","executionInfo":{"status":"ok","timestamp":1637743888899,"user_tz":-540,"elapsed":273,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}}},"source":["from sklearn.metrics import accuracy_score, confusion_matrix\n","import seaborn as sns"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"a3fOYzCXHs3e","executionInfo":{"status":"ok","timestamp":1637743898385,"user_tz":-540,"elapsed":1024,"user":{"displayName":"hyungyu kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSdKyZSuYLTeMQBWw-25Pn1ZyxfQiHrQbqNK2e=s64","userId":"13011597531167301511"}},"outputId":"0e5f92d3-f774-44d2-96f5-2f9c8e7c9b73"},"source":["model = load_model('models/%s.h5' %(start_time))\n","\n","y_pred = model.predict(x_val/255.)\n","y_pred_logical = (y_pred>0.5).astype(np.int)\n","\n","print('test acc: %s' %accuracy_score(y_val, y_pred_logical))\n","cm = confusion_matrix(y_val, y_pred_logical)\n","sns.heatmap(cm, annot=True)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["test acc: 1.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fbcb7f3ae90>"]},"metadata":{},"execution_count":16},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"dark"}}]},{"cell_type":"code","metadata":{"id":"tev8kjr8Hs-p"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2rAERdcHtBO"},"source":[""],"execution_count":null,"outputs":[]}]}